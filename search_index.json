[["index.html", "Mijn Data Sciences portfolio Door: Stephanie de Wit Datum: 12-06-2022 Welkom! Tijdens het tweede deel van de Data Sciences for Biology minor te Hogeschool Utrecht, heb ik gewerkt aan een portfolio van mijn vaardigheden tot nu toe. Dit portfolio is gebouwd met het CRAN {bookdown} R package en wordt hier gepubliceerd via GitHub Pages. 1 Over mij", " Mijn Data Sciences portfolio Door: Stephanie de Wit Datum: 12-06-2022 Welkom! Tijdens het tweede deel van de Data Sciences for Biology minor te Hogeschool Utrecht, heb ik gewerkt aan een portfolio van mijn vaardigheden tot nu toe. Dit portfolio is gebouwd met het CRAN {bookdown} R package en wordt hier gepubliceerd via GitHub Pages. 1 Over mij Ik ben een nieuwsgierige, scherpe en gedreven Life Sciences studente van 24 jaar oud. Momenteel rond ik mijn derde studiejaar af met een Data Sciences minor en ben ik opzoek naar een uitdagende afstudeerstage. Ik smul van studiemateriaal over genetica, immunologie en tumorcelbiologie en werk graag met moleculair biologische technieken, celkweek en eiwit analyse technieken. Het is mijn ambitie om als moleculair bioloog onderzoek te doen naar het ontstaan, voorkomen en bestrijden van ziekten. Als ik niet aan het lezen ben in Campbell, Biology of documentaires kijk over het heelal, ga ik graag tafelen met vrienden en familie, naar het museum en op stedentripjes. Header afbeelding: afkomstig uit een online artikel van The Economist "],["vaardigheid-1-semi-reproduceerbare-data-analyseren.html", "2 Vaardigheid 1: Semi-reproduceerbare data analyseren 2.1 C. elegans kweekplaat experiment 2.2 Normalisatie met het {drc} package", " 2 Vaardigheid 1: Semi-reproduceerbare data analyseren De Reproducible Research beweging streeft ernaar dat onderzoekers al hun data, gebruikte methodes en codes openbaar maken. Dit verhoogt de reproduceerbaarheid van hun onderzoek en daarmee de kwaliteit ervan, evenals het algehele vertrouwen in de wetenschap. Hieronder laat ik zien dat ik overweg kan met data die verkregen is volgens een niet- of semi-reproduceerbare workflow. 2.1 C. elegans kweekplaat experiment Volwassen C. elegans nematoden zijn blootgesteld aan verschillende concentraties naftaleen, 2,6-di-isopropylnaftaleen en decaan, waarna is onderzocht of deze blootstellingen en negatief effect hebben op het aantal nakomelingen. S-medium dient als negatieve controle voor dit effect, 1,5% ethanol dient als positieve controle. De belangrijkste variabelen in de gekregen dataset (CE.LIQ.FLOW.062_Tidydata.xlsx) zijn: expType: de behandelconditie. RawData: het aantal nakomelingen geteld na de incubatietijd. compName: de generieke naam van de stof. compConcentration: de concentratie van de stof. Gebruikte CRAN packages voor de analyse: {ggplot2} Het Excel bestand heeft een tidy opmaak, maar bevat verschillende, onnodige variabelen die voor elke onderzochte vial dezelfde waarde aannemen zijn. De stof concentraties worden gegeven in nanomolair maar de concentratie ethanol wordt gegeven in procent. Verder missen vijf ‘RawData’ waarden. Het bestand bevat één sheet waarin de aanpassingen aan de parameter levels zijn gedocumenteerd en één sheet met alle unieke level opties per parameter. Er mist wel een exacte beschrijven van de parameters en hun levels: zijn de graden in Celsius? Betekent het ‘pct’ level van ‘compConcentration’ procent? #Lees het bestand in in R als tibble: elegans&lt;-read_excel(here::here(&quot;data_raw&quot;, &quot;data01_assignment_1.1&quot;, &quot;CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) #view(elegans) #summary(elegans) De vijf missende ‘RawData’ waarden kunnen uit de tabel verwijderd worden, maar {ggplot2} grafieken negeren ze automatisch. Er moet het één en ander aangepast worden aan de ingelezen data voordat een fatsoenlijke grafiek gemaakt kan worden: A) Na het importeren van de data naar R, zijn de variabelen van data type veranderd. ‘RawData’ is van het data type double geworden, dit moet integer zijn. Als de ‘compConcentration’ variabele, nu van het data type character, niet als double wordt opgegeven, ontstaat een foute X-as. De variabele ‘compName’ moet tot factor gemaakt worden voor gebruik in een {ggplot2} grafiek. B) Het percentage ethanol moet als volgt omgerekend worden naar nanomolair: nMol/L = (percentage ethanol * dichtheid in g/L ) / (molaire massa in g/mol * 100) * 1.000.000 1.5% ethanol = 256891.7 nmol/L 0.5% ethanol = 85630.6 nmol/L De dichtheid van het gebruikte ethanol is nodig om de percentages om te rekenen naar nanomolair, maar niet gegeven. Daarom wordt uitgegaan van de standaard 789 g/L. #Verander de ethanol concentraties van procent naar nM: elegans_nM &lt;- elegans elegans_nM$compConcentration &lt;- elegans_nM$compConcentration %&gt;% str_replace_all(&quot;1.5&quot;,&quot;256891.686564&quot;) elegans_nM$compConcentration &lt;- elegans_nM$compConcentration %&gt;% str_replace_all(&quot;0.5&quot;,&quot;85630.562188&quot;) elegans_nM$compUnit &lt;- elegans_nM$compUnit %&gt;% str_replace_all(&quot;pct&quot;,&quot;nM&quot;) Verder: zet de stof concentraties op een log10-schaal en voeg variatie toe aan de punten tegen overlap. elegans_nM %&gt;% ggplot(aes(x = log10(as.double(compConcentration)), y = as.integer(RawData))) + geom_point(aes(colour = as.factor(compName), shape = as.factor(expType)), size = 1.5, position = &quot;jitter&quot;) + #Jitter voegt wat variatie toe tegen overlap tussen de punten labs(x = &quot;Log10(stof concentratie) (nM)&quot;, y = &quot;Aantal nakomelingen na blootstelling&quot;, colour = &quot;Stof&quot;, shape = &quot;Conditie&quot;) + theme_bw() Figure 2.1: Aantal C. elegans nakomelingen na verschillende blootstellingen (versie 1). Het aantal nakomelingen is geteld na incubatie voor een onbekende tijd van nematoden in S-medium en bij verschillende concentraties naftaleen, 2,6-di-isopropylnaftaleen, decaan en ethanol. De negatieve controle S-medium is gelijk gesteld aan een ‘compConcentration’ van 0 ‘pct’, vandaar dat S-medium niet in de grafiek verschijnt. De log10 van 0 bestaat niet. Wat nog resteert is het normaliseren van de data. We zijn geïnteresseerd in hoeveel nematoden er meer of minder worden geboren na incubatie met een stof ten opzichte van de normale situatie. Dit is niet aftelezen aan de bovenstaande grafiek, omdat het aantal nakomelingen van de negatieve controle wegvallen. Ik normaliseer door van elke meting het aantal nakomelingen uit te drukken als fractie van het gemiddelde aantal nakomelingen na incubatie in S-medium. # Gemiddeld aantal nakomelingen negatieve controle berekenen: controlNegative &lt;- elegans_nM %&gt;% filter(expType == &quot;controlNegative&quot;) %&gt;% select(RawData) %&gt;% as_vector() mean(controlNegative) ## [1] 85.9 # Normaliseer hiermee de rest: elegans_norm &lt;- elegans_nM %&gt;% mutate(RawData_normalized = RawData / mean(controlNegative)) elegans_norm %&gt;% ggplot(aes(x = log10(as.double(compConcentration)), y = as.integer(RawData_normalized))) + geom_point(aes(colour = as.factor(compName), shape = as.factor(expType)), size = 1.5, position = &quot;jitter&quot;) + labs(x = &quot;Log10(stof concentratie) (nM)&quot;, y = &quot;Fractie nakomelingen na blootstelling&quot;, colour = &quot;Stof&quot;, shape = &quot;Conditie&quot;) + theme_bw() Figure 2.2: Fracties C. elegans nakomelingen na verschillende blootstellingen. Voor elke blootstelling aan één van de stoffen in een bepaalde concentratie is de fractie nakomelingen berekend, relatief een het aantal nakomelingen binnen de negatieve controle. Er zijn alleen negatieve fracties aanwezig door de jitter optie. Conclusie Voor de positieve controle geldt, dat er duidelijk minder nematoden geboren worden na incubatie in 1,5% ethanol ten opzichte van in S-medium (fractie &lt;&lt; 1). Bij stof concentraties lager dan ~ 0.06 nM (oftewel log10’s lager dan -1.25) worden er evenveel, minder of meer nematoden geboren als binnen de negatieve controle. Bij deze concentraties is er dus geen effect op het aantal nakomelingen. Voor incubatie bij hogere concentraties van de drie geteste stoffen geldt, dat er minder nematoden geboren worden dan binnen de negatieve controle (fractie &lt;&lt; 1). 2.2 Normalisatie met het {drc} package Op data zoals bovenstaande wordt gewoonlijk een dosis-response analyse uitgevoerd. Dit kan met het CRAN package {drc}. Hieronder volgt een versimpelde workflow voor een analyse met het log-logistic model. “RPubs - Four-Parameter Log-Logistic Model” (n.d.) beschrijft het modelleren met het {drc} package alsvolgt: De gemiddelde respons (y) wordt gekarakteriseerd met een functie (f), die afhankelijk is van de dosis (x) en het type respons (β). Het type respons is afhankelijk van de distributie van de data. Dus: voor een dosis x zullen de responsen y gedistributeerd zijn rond functie f volgens β. Generalized log-logistic function: f(x, (b, c, d, e)) = c + (d - c)/(1 + exp(b(logx) - log(e))). Fit het log-logistic model van ‘llogistic()’ met ‘drm()’ volgens ‘drm(a, b = , c = llogistic(), d = , …)’ (“The Three-Parameter Log-Logistic Function — LL.3” n.d.; “LL.3: The Three-Parameter Log-Logistic Function in Drc: Analysis of Dose-Response Curves” n.d.). Verkrijg een schatting van de het maximum, het minimum, de ED50 en de richtingscoëfficient met hun bijbehorende standaard errors, t-waarden en p-waarden met ‘summary(drm_model)’ (“The Three-Parameter Log-Logistic Function — LL.3” n.d.; “LL.3: The Three-Parameter Log-Logistic Function in Drc: Analysis of Dose-Response Curves” n.d.; “RPubs - Four-Parameter Log-Logistic Model” n.d.). Test de fit van het model met bijv. de goodness-of-fit test ‘modelFit(drm_model)’ (“The Three-Parameter Log-Logistic Function — LL.3” n.d.; “LL.3: The Three-Parameter Log-Logistic Function in Drc: Analysis of Dose-Response Curves” n.d.; “RPubs - Four-Parameter Log-Logistic Model” n.d.). Verkrijg de betrouwbaarheidsintervallen voor bovengenoemde vier parameters met ‘confint(drm_model)’ (“RPubs - Four-Parameter Log-Logistic Model” n.d.). Bereken m.b.v. de bovengenoemde vier parameters de IC50 (“RPubs - Four-Parameter Log-Logistic Model” n.d.). Plot de dosis-respons curve met ‘plot(drm_model)’. Argument ‘log = ““’ schakelt de default logaritmische x-as uit, ‘broken = TRUE’ geeft ook de dosis 0 weer en er kan genormaliseerd worden: ‘norm = TRUE’ en ‘normref = 1’ (“The Three-Parameter Log-Logistic Function — LL.3” n.d.; “LL.3: The Three-Parameter Log-Logistic Function in Drc: Analysis of Dose-Response Curves” n.d.; “RPubs - Four-Parameter Log-Logistic Model” n.d.; Ritz et al. 2015). Voor het C. elegans experiment is het gemiddelde aantal nakomelingen binnen de negatieve controle ook gelijk gesteld aan 1 en het aantal nakomelingen uitgedrukt als fractie daarvan. "],["vaardigheid-2-een-open-source-analyse-reproduceren.html", "3 Vaardigheid 2: Een Open Source analyse reproduceren 3.1 Ripeta criteria 3.2 Analyse reproduceren", " 3 Vaardigheid 2: Een Open Source analyse reproduceren Met onderstaande uitwerkingen wil ik laten zien, dat ik artikelen op reproduceerbaarheid kan beoordelen en (een stukje van) een analyse kan nabootsen waarvan de gebruikte code openbaar is gemaakt. 3.1 Ripeta criteria De reproduceerbaarheid van een artikel wordt gescored aan de hand van de Ripeta criteria. Ik heb het volgende Open Source artikel van Pubmed Central op reproduceerbaarheid beoordeeld: Chaimayo, C., Kaewnaphan, B., Tanlieng, N. et al. Rapid SARS-CoV-2 antigen detection assay in comparison with real-time RT-PCR assay for laboratory diagnosis of COVID-19 in Thailand. Virol J 17, 177 (2020) (zie tabel 3.2). Dit artikel vergelijkt de prestaties van een SARS-CoV-2 antigeen sneltest, de Standard™ Q COVID-19 Ag kit van Biosensor®, met die van een RT-qPCR, specifiek de Allplex™ 2019-nCoV Assay van Seegene®. Een RT-qPCR vormde op het moment van publicatie als de gouden standaard voor het diagnosticeren van SARS-CoV-2 infecties. Er zijn 454 neus-keel monsters afgenomen bij participanten die mogelijk besmet waren met COVID-19. Elk monster is gebruikt voor een RT-qPCR en een antigeen sneltest. De antigeen sneltest liet een gevoeligheid en specificiteit zien vergelijkbaar aan de RT-qPCR en kan gebruikt worden voor screening op SARS-CoV-2 (Chaimayo et al. 2020). Onderstaande tabel is overgenomen uit het artikel en laat zien dat voor zes participanten de (ruwe) uitslagen van de PCR en antigeen sneltest niet overeenkwamen. Table 3.1: Participanten met tegenstrijdige PCR en sneltest uitslagen Gender Age Initial diagnosis Specimen type PCR Ct-value E PCR Ct-value RdRP PCR Ct-value N Rapid Ag test result Interpretation F 33 Pneumonia NP swab + throat swab 31.18 39.20 35.54 Negative False negative F 67 Pre-operative NP swab + throat swab &gt; 40 &gt; 40 &gt; 40 Positive False positive M 75 Pre-operative NP swab + throat swab &gt; 40 &gt; 40 &gt; 40 Positive False positive F 61 Pre-operative NP swab + throat swab &gt; 40 &gt; 40 &gt; 40 Positive (weakly) False positive F 83 Pre-operative NP swab + throat swab &gt; 40 &gt; 40 &gt; 40 Positive (weakly) False positive F 64 Pre-operative NP swab + throat swab &gt; 40 &gt; 40 &gt; 40 Positive (weakly) False positive Table 3.2: Ripeta criteria scores voor Chutikarn et al. 2020 Transparancy Criteria Definition Response Type Score Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. Binary TRUE Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. Binary TRUE Data Location Where the article’s data can be accessed, either raw or processed. Found Value All data generated or analysed are included in the published article and its additional files. Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. Binary; Found Value Bangkok, Thailand Author Review The professionalism of the contact information that the author has provided in the manuscript. Found Value Navin Horthongham is corresponding author. navin.hor@mahidol.ac.th Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. Binary TRUE Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. Binary TRUE Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. Binary FALSE 3.2 Analyse reproduceren Voor de reproductie heb ik een Open Source paper gekozen uit een gegeven studie die heeft onderzocht hoe reproduceerbaar papers gepubliceerd onder het Open Source beleid nou écht zijn. Van dit paper heb ik een stuk code gereproduceerd. Het gekozen paper uit de gegeven studie (Paper06): Arthur G. Samuel, Psycholinguists should resist the allure of linguistic units as perceptual units, Journal of Memory and Language (2020) De bijbehorende code (Reproducing.Rmd) en dataset (osfstorage-archive/Exp2_Final_Adaptors_CVtestitems) zijn te vinden op OSF. De codes in deze RMarkdown zijn gebruikt om de figuren te maken die in dit paper weergegeven worden. Op een schaal van 1 (zeer slecht) tot 5 (zeer goed) geef ik de leesbaarheid van de codes in dit bestand een 2. Hieronder reproduceer ik een deel van de data om figuur 2 uit het paper na te maken. Het koste me moeite om dit figuur te reproduceren, met een score van 3 op een schaal van 1 (zeer moeilijk) tot 5 (zeer makkelijk). Een stuk code met een helperfunctie van de RMarkdown auteur voor het inlezen van de data: knitr::opts_chunk$set(echo = TRUE) rm(list=ls()) if(!require(tidyverse)){install.packages(&#39;tidyverse&#39;)} if(!require(lme4)){install.packages(&#39;lme4&#39;)} if(!require(readr)){install.packages(&#39;readr&#39;)} read_exp_data &lt;- function(filenames_BF_ID, to_skip){ BF_ID &lt;- NULL for (i in filenames_BF_ID){ adaptor &lt;- substring(i, 1, 1) # first letter of the filename temp &lt;- read.csv(i, skip = to_skip) %&gt;% select(1:8) temp1 &lt;- temp %&gt;% select(1,2,3,4) if (grepl(&#39;X&#39;, colnames(temp1)[3])){ temp1 &lt;- NULL } else { temp1 &lt;- temp1 %&gt;% mutate(participant.id = colnames(temp1)[3], adaptor = adaptor) %&gt;% rename(response = colnames(temp1)[3], RT = colnames(temp1)[4]) } temp2 &lt;- temp %&gt;% select(1,2,5,6) if (grepl(&#39;X&#39;, colnames(temp2)[3])){ temp2 &lt;- NULL } else { temp2 &lt;- temp2 %&gt;% mutate(participant.id = colnames(temp2)[3], adaptor = adaptor) %&gt;% rename(response = colnames(temp2)[3], RT = colnames(temp2)[4]) } temp3 &lt;- temp %&gt;% select(1,2,7,8) if (grepl(&#39;X&#39;, colnames(temp3)[3])){ temp3 &lt;- NULL } else { temp3 &lt;- temp3 %&gt;% mutate(participant.id = colnames(temp3)[3], adaptor = adaptor) %&gt;% rename(response = colnames(temp3)[3], RT = colnames(temp3)[4]) } BF_ID &lt;- rbind(BF_ID, temp1, temp2, temp3) } return(BF_ID) } Een stuk code voor het berekenen van het aantal participanten in (waarschijnlijk) de ‘No-Release’ conditie: wd &lt;- here::here(&quot;data_raw&quot;, &quot;data02_assignment_1.2&quot;) setwd(wd) filenames_ID &lt;- list.files(pattern = &quot;ID&quot;) ID &lt;- read_exp_data(filenames_ID, to_skip =4) %&gt;% mutate(participant.id = tolower(participant.id)) nlevels(as.factor(ID$participant.id)) ## [1] 33 Een stuk code voor het berekenen van het aantal participanten in (waarschijnlijk) de ‘adaptation’ conditie: setwd(wd) filenames_FAD &lt;- list.files(pattern = &quot;FAD&quot;) FAD &lt;- read_exp_data(filenames_FAD, to_skip =6) nlevels(as.factor(FAD$participant.id)) ## [1] 34 Een stuk code voor het filteren van participanten uit de (waarschijnlijk) ‘No-Release’ conditie: setwd(wd) # filtering to_filter &lt;- ID %&gt;% drop_na() %&gt;% mutate(adaptor = ifelse(adaptor == &quot;B&quot;, &quot;B&quot;, &quot;D&quot;), B = ifelse(response == 4, 1, 0), D = ifelse(response == 1, 1, 0), adaptorB = ifelse(adaptor == &quot;B&quot;, 1, -1), adaptorD = ifelse(adaptor == &quot;D&quot;, 1, -1), Bgrade = parse_number(as.character(AudioWaveFile1))-1) %&gt;% filter(Bgrade == 1 | Bgrade == 7) %&gt;% group_by(participant.id, Bgrade) %&gt;% summarize(D_response = mean(D)) %&gt;% pivot_wider(id_cols = participant.id, names_from = Bgrade, values_from = D_response) %&gt;% mutate(diff = `1` - `7`) %&gt;% filter(diff &lt; 0.6) to_filter ## # A tibble: 4 × 4 ## # Groups: participant.id [4] ## participant.id `1` `7` diff ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 asav 0.944 0.389 0.556 ## 2 kjol 0.722 0.194 0.528 ## 3 kpao 0.972 0.833 0.139 ## 4 ttys 0.972 1 -0.0278 Deze codes geven mij dezelfde uitkomst als de RMarkdown auteur. Nu kan ik een figuur, figuur 2 uit het paper, reproduceren: wd &lt;- here::here(&quot;data_raw&quot;, &quot;data02_assignment_1.2&quot;) setwd(wd) FAD &lt;- FAD %&gt;% drop_na() %&gt;% filter(! participant.id %in% to_filter$participant.id) %&gt;% mutate(B = ifelse(response == 1, 1, 0), D = ifelse(response == 4, 1, 0), adaptorB = ifelse(adaptor == &quot;B&quot;, 1, -1), adaptorD = ifelse(adaptor == &quot;D&quot;, 1, -1), Bgrade = parse_number(as.character(WaveFile))-1,#AFAIU the lower the number the closer to B, but I might be wrong RT = RT*1000) # Figure 2 FAD %&gt;% group_by(participant.id, Bgrade, adaptor) %&gt;% summarize(part_mean = mean(D)) %&gt;% group_by(Bgrade, adaptor) %&gt;% summarize(acc = mean(part_mean)) %&gt;% ggplot(aes(x = Bgrade, y = acc, color = adaptor)) + geom_point() + geom_line() Deze figuur ziet er volgens de auteur hetzelfde uit als figuur 2 in het paper De vormen kloppen, maar de Y-as en as titels zijn door de RMarkdown auteur anders gekozen. De Y-as laat fracties zien i.p.v. percentages. Dit kan gemakkelijk aangepast worden: FAD %&gt;% group_by(participant.id, Bgrade, adaptor) %&gt;% summarize(part_mean = mean(D)) %&gt;% group_by(Bgrade, adaptor) %&gt;% summarize(acc = mean(part_mean) * 100) %&gt;% ggplot(aes(x = Bgrade, y = acc, color = adaptor)) + geom_point() + geom_line() + theme_classic() + scale_colour_manual(values=c(&quot;blue&quot;,&quot;red&quot;),labels=c(&quot;B adapt&quot;,&quot;D adapt&quot;), name = &quot;&quot;) + labs(title=&quot;Released Final Position Adaptors on CV Test Series&quot;, x = &quot;Continuum Step&quot;, y = &quot;Percent \\&quot;d\\&quot; Report&quot;) + ylim(0,100) Figure 3.1: Identification of the members of the /ba/-/da/ test series, as a function of the adaptation condition, for adaptors that included released final stops. After adaptation with final-/d/ words (red curve/squares) identification as “D” was reduced compared to adaptation with final-/b/ words (blue curve/circles). Bovenstaand onderschrift is letterlijk overgenomen uit figuur 2 van het paper zelf. "],["vaardigheid-3-folder-structuur-gebruiken-volgens-de-guerilla-principles.html", "4 Vaardigheid 3: Folder structuur gebruiken volgens de Guerilla Principles", " 4 Vaardigheid 3: Folder structuur gebruiken volgens de Guerilla Principles Hieronder demonstreer ik met een folder tree van de Data Sciences for Biology 1 DAUR2 lessen, hoe een goede folder structuur er volgens de Guerilla Principles uit ziet. De principes opgesomt: De RMarkdown bestanden van een project staan in de folder ‘Rmd’. Geschreven functions die worden aangehaald in de RMarkdowns staan in de folder ‘R’. Scripts met overige code die aangehaald worden in de RMarkdowns staan in de folder ‘code’. Ruwe data staan in de folder ‘data_raw’. Binnen deze folder heeft elke dataset een eigen folder In deze folder staat een README bestand met informatie over hoe de dataset tot stand is gekomen, een folder ‘supporting’ voor benodigdheden en eventueel een folder ‘v01’ voor een oudere versie van de dataset. Opgeschoonde en/of tidy gemaakte, ruwe data staan in sub-folders in de folder ‘data’. In deze folder is ook een Excel bestand aanwezig met een overzicht van aanwezige data, genaamd ‘data-log’. In de folder ‘images’ staan de afbeeldingen die gebruikt worden in de RMarkdowns. In de folder ‘doc’ worden overige documenten opgeslagen. #install.packages(&quot;fs&quot;) library(fs) dir_tree(path = here::here(&quot;DAUR2&quot;)) ## C:/Users/Dvand/steph/portfolio_book/DAUR2 ## ├── data ## │ └── data-log.xlsx ## ├── data_raw ## │ ├── data01_rnaseq_airway ## │ │ └── README.txt ## │ ├── data02_rnaseq_ipsc ## │ │ └── README.txt ## │ ├── data03_rnaseq_onecut ## │ │ └── README.txt ## │ ├── data04_metagenomics_reader_data ## │ │ ├── HU1_MOCK1_L001_R1_001_fastqc.html ## │ │ ├── HU1_MOCK1_L001_R1_001_fastqc.zip ## │ │ ├── HU1_MOCK1_L001_R2_001_fastqc.html ## │ │ ├── HU1_MOCK1_L001_R2_001_fastqc.zip ## │ │ ├── mock1.bracken ## │ │ ├── mock1.report ## │ │ ├── mock1_bracken_species.biom ## │ │ ├── mock1_bracken_species.report ## │ │ ├── README.txt ## │ │ └── supporting ## │ │ └── setup_meta_env.yml ## │ └── data05_metagenomics_formative_data ## │ └── README.txt ## ├── daur2.Rproj ## ├── doc ## │ └── EindopdrachtDAUR2_V6.pdf ## ├── images ## │ ├── meta_lesson6_R1.png ## │ ├── meta_lesson6_R2.png ## │ └── screenshot_BCLXL_2_reversed.png ## └── Rmd ## ├── Eindopdracht_DAUR2_V6.html ## ├── Eindopdracht_DAUR2_V6.Rmd ## ├── formatieve_opdracht_rnaseq.html ## ├── formatieve_opdracht_rnaseq.Rmd ## ├── les1.Rmd ## ├── les2.Rmd ## ├── les3.Rmd ## ├── les4.Rmd ## ├── les6.Rmd ## ├── les7.Rmd ## └── les8.Rmd "],["vaardigheid-4-opmaken-met-rmarkdown-en-html-syntax.html", "5 Vaardigheid 4: Opmaken met RMarkdown en HTML syntax", " 5 Vaardigheid 4: Opmaken met RMarkdown en HTML syntax Er zijn eindeloos veel opties om een RMarkdown bestand overzichtelijker en mooier te maken. Met een CV laat ik zien, dat ik daartoe overweg kan met RMarkdown syntax en een RMarkdown kan koppelen aan een CSS bestand. Ik heb het template ‘HTML resume’ van het CRAN package {pagedown} gebruikt om met RMarkdown een CV als PDF bestand te genereren. Het is niet mogelijk om dergelijke templates toe te voegen aan een Gitbook als deze. RMarkdown code voor YAML header: #--- #title: &quot;Stephanie&#39;s resume&quot; #author: Stephanie de Wit #date: &quot;22-05-2022&quot; #output: # pagedown::html_resume: # css: # - override.css # - resume # self_contained: false #knit: pagedown::chrome_print #--- HTML code in CSS bestand: #* { # /* Override default margins*/ # --pagedjs-margin-right: 0.2in; # --pagedjs-margin-left: 0.2in; # --pagedjs-margin-top: 0.2in; # --pagedjs-margin-bottom: 0.2in; #} # # #:root{ # --sidebar-width: 15rem; /* side bar width */ # --sidebar-background-color: #2EB3B3; # --decorator-border: 2px solid #35D1D1; /* change color and thickness of timeline */ # #} # #.decorator::after{ # background-color: #35D1D1; /* change color timeline dots */ # #} # # #/* Define the font family here */ #body{ # font-family: &quot;Roboto&quot;, sans-serif; # #} RMarkdown code voor body: #Aside #========================================================#======================== # # #![Stephanie de Wit](https://avatars.githubusercontent.com/u/103999467?s=400&amp;u=9d6a4da194685107008731008461da14c27693fa&amp;v=4){width=90%} # # #Contact Info {#contact} #-------------------------------------------------------------------------------- # #- &lt;i class=&quot;fa fa-envelope&quot;&gt;&lt;/i&gt; stephanie.dewit@student.hu.nl #- &lt;i class=&quot;fa fa-github&quot;&gt;&lt;/i&gt; [github.com/stephaniedewit](https://github.com/stephaniedewit) #- &lt;i class=&quot;fa fa-phone&quot;&gt;&lt;/i&gt; +31 6******** # #Soft skills {#skills} #-------------------------------------------------------------------------------- # #- Perseverance # #- Precision # #- Independence # #- Organizational # #- Social skills # #Hard skills {#skills} #-------------------------------------------------------------------------------- # #- Experienced in cell culture, recombinant DNA #techniques and protein analysis. # #- Skilled in R and Bash. # #- Experienced with statistical analysis and next generation sequencing data analysis. # #Main #================================================================================ # #Stephanie de Wit {#title} #-------------------------------------------------------------------------------- # #### Currently searching for a graduation internship # #Enthusiastic, third-year Life Sciences student with a grade average of 8.8, looking for a challenging graduation internship. I am fond of study material about genetics, immunology and tumor cell biology and enjoy working with recombinant DNA techniques, cell culture and protein chromatography. It is my ambition to conduct research into the origin, prevention and control of diseases as a molecular biologist. # # #Education {data-icon=graduation-cap data-concise=true} #-------------------------------------------------------------------------------- # #### Institute for Life sciences &amp; Chemistry, Hogeschool Utrecht # #Biologie en Medisch Laboratoriumonderzoek (Life Sciences) # #Utrecht, The Netherlands # #2019 - today # #::: concise #- __Minor (today): _Data Sciences for Biology_ 1 &amp; 2__. Content: Bash, _next generation sequencing_, RStudio, _RNA-sequencing_, _metagenomics_, GitHub, SQL. #- __Specialisation: _Biomolecular Research_ (BMR)__. Courses: Biotechnologie, Projecticum _Biomolecular Research_, Practicum Moleculaire Biologie, _Advanced Labtools_, Tumorcelbiologie. #::: # # Workexperience {data-icon=suitcase} #-------------------------------------------------------------------------------- # #### Schoolproject: Projecticum Biomolecular Research # #Performed in collaboration with Genmab BV. # #Utrecht, The Netherlands # #september 2021 - januari 2022 # #::: concise #Using _size exclusion chromatography_ we investigated whether Hexabody® antibodies have a lower tendency to hexamerize after oxidation. #::: "],["vrije-besteding-een-nieuwe-skill-ontwikkelen.html", "6 Vrije besteding: een nieuwe skill ontwikkelen 6.1 Introductie 6.2 Deel 1: Oefenen met de vignette ‘LCMS data preprocessing and analysis with xcms’ 6.3 Deel 2: xcms gebruiken voor een eigen analyse van de {faahKO} monsters 6.4 Afronding", " 6 Vrije besteding: een nieuwe skill ontwikkelen 6.1 Introductie Tijdens de DSFB2 Workflows lessen heb ik 32 uur vrij te besteden gekregen om te werken aan een nieuwe Data Science skill. Deze skill heb ik gekozen door mijzelf af te vragen waar ik over twee jaar wil zijn. Ik zie mijzelf dan als biomedisch analist een bijdrage leveren aan onderzoek naar de ontwikkeling, bestrijding en genezing van ziekten. Specifiek zou ik graag onderzoek doen naar kanker of hersenziekten met celkweek, gentherapie en eiwit analyse technieken. Daarbij gebruik ik de vaardigheden die ik heb geleerd tijdens de Data Sciences for Biology minor om mijn onderzoeksresultaten te analyseren en presenteren. Eiwit analyse technieken waarin ik specifiek geïnteresseerd ben, zijn High-Performance Liquid Chromatography (HPLC) en massaspectrometrie (MS). Uiteindelijk wil ik doorstuderen tot moleculair bioloog en grootschalige onderzoeken opzetten. Tijdens mijn BMR specialisatie projecticum heb ik gewerkt met een HPLC. De UV-detectie resultaten kwamen op de computer binnen via de software Clarity Lite, waarna handmatig data van interesse is gekopieerd naar een Excel bestand. Van deze data zijn tabellen gemaakt in PowerPoint en grafieken in Excel. Statistische tests zijn uitgevoerd in SPSS. Om het aantal handmatige stappen en de vatbaarheid voor fouten van deze analyse te verminderen, ben ik gaan onderzoeken of ik de ruwe Clarity Lite data kan exporteren en aan een R package kan ‘voeren’ voor een volledige data analyse in RStudio. Al vrij snel bleek ik geen R package te kunnen vinden voor de analyse van (HP)LC data. Ik ben wel een handvol packages tegengekomen voor analyses van LC-MS data (zie tabel 6.1). Vloeistofchromatografie en massaspectrometrie zijn tegenwoordig vrijwel niet meer los van elkaar te denken. Daarnaast wil ik üperhaupt meer ervaring opdoen met massaspectrometrie. Hierom heb ik ervoor gekozen om mij voor 32 uur te richten op het analyseren van LC-MS data met R als nieuwe skill. Table 6.1: Gevonden R packages voor LC-MS of GC-MS data analyse Algorithm Designed for Used Dimensions Environment Visual tools amsrpm LC-MS RT, I, m/z R No msInspect/AMT LC-MS/MS RT, I, m/z Java, R No PETAL LC-MS RT, m/z R No Podwojski LC-MS RT, I, m/z R No ptw LC-MS I, RT R No xcms LC-MS RT, I, m/z R Yes Note: Deze tabel is een onderdeel van de tabel ‘S1. Summary of published algorithms implemented … datasets.’ uit M. Ottensmann et al., 2018. De packages waar ik me verder in heb verdiept, zijn groen gekleurd. 6.1.1 Plan van Aanpak Ik heb een kort plan opgesteld waarmee ik het leren van deze nieuwe skill ga aanpakken. Eén week voordat het portfolio moet worden ingeleverd, ga ik echt van start. Table 6.2: Urenplanning Stap Wat Schatting tijdsbelasting Werkelijke tijdsbelasting 1 Oriënteren op de R packages die beschikbaar zijn voor LC-MS data analyse. 2 uur ~ 1,5 uur 2 Twee á drie packages kiezen en hier verder in verdiepen.** 2,5 uur ~ 1,5 uur 3 De packages proberen te installeren. 2 uur 2 uur 4 Eén package kiezen en een tutorial o.i.d. over deze package volgen. ~ 8 uur 11 uur 5 Het package zelf proberen toe te passen op andere data. ~ 10 uur 12,5 uur 6 Eigen code duidelijk uitschrijven in portfolio. max. 4 uur ~ 5 uur Note: *Ik maak een afspraak met een docent voor gebruik van de HPLC computer op HL7. **Criteria: er moet tenminste één uitgebreide tutorial o.i.d. met bijbehorende dataset beschikbaar zijn voor het package, evenals nieuwe data om zelf een code voor te schrijven. Indien er tijd over is, probeer ik een (korte) tutorial te vinden van een ander package voor LC-MS analyse. Mocht het nou allemaal nergens op uitdraaien, is mijn plan B om de analyse van mijn BMR projecticum volledig te automatiseren in R. Dit is dan geen nieuwe skill, maar wel een volledig zelf bedachte analyse en zelfgeschreven code. Het is me niet gelukt om het {amsrpm} package, beschikbaar als amsrpm.tar.gz, te installeren. Van het {ptw} package is een publieke repository met demo’s beschikbaar, maar de meeste informatie kon ik vinden over het {xcms} package. Er bestaat een publieke repository met verschillende vignettes waarin het package uitgebreid wordt gedemonstreerd. Belangrijk is ook dat de vignettes gebruik maken van ruwe data beschikbaar in andere ‘installeerbare’ packages, zoals {faahKO}. Na het kopiëren van de repository kon ik met ‘install()’ het package installeren. Hiervoor moeten RStudio versie 4.2 en RTools versie 4.2 gebruikt worden. Buiten de repository om kunnen de functions uit dit package door een ieder geïnstalleerd worden met ‘devtools::install(“sneumann/xcms”)’. 6.2 Deel 1: Oefenen met de vignette ‘LCMS data preprocessing and analysis with xcms’ Het vignette ‘LCMS data preprocessing and analysis with xcms’, te vinden op BioConductor of onder ‘xcms/vignettes/xcms.Rmd’ in de repository, demonstreert hoe het {xcms} package gebruikt kan worden voor de import, inspectie, preproccesing en eigenlijke analyse van LC-MS data. Daarvoor maakt het gebruik van data uit een studie van Alan Saghatelian et al. uit 2004, beschikbaar als {faahKO} package. Deze onderzoekers zijn opzoek gegaan naar lipiden in het zoogdier brein die gereguleerd worden door het enzym fatty acid amide hydrolase (FAAH). Daartoe hebben ze met LC-MS het metaboloom in kaart gebracht van wildtype muizen en van knock-out muizen met een inactief FAAH gen (Saghatelian et al. 2004). In het {faahKO} package is in NetCDF format de ruwe, positive ion en centroid mode LC-MS data aanwezig van ruggengraatmonsters van wild-type (WT) en knock-out (KO) muizen. Het vignette beperkt de analyse tot zes WT muizen en zes KO muizen (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). Ik heb deze vignette grondig bestudeerd en de code gereproduceerd om te oefenen met het package, evenals om te checken of alle functions ook echt werken op mijn laptop. 6.3 Deel 2: xcms gebruiken voor een eigen analyse van de {faahKO} monsters De nieuwgeleerde analyse heb ik toegepast op de monsters ko18, ko19, wt18 en wt19 uit het {faahKO} package. Deze monsters zijn niet meegenomen in de voorbeeld analyse. Ik begin met het inladen van een workspace met alle benodigde objects, omdat bepaalde functions tijdens het bouwen van dit Gitbook BiocParallel errors kunnen geven (bekend voor het {xcms} package). Deze functions zijn uitgezet met een ‘#’. 6.3.1 1) Data import # Installeer de volgende packages via CRAN of BioConductor en laad ze vervolgens met: library(xcms) library(faahKO) library(RColorBrewer) library(pander) library(magrittr) library(pheatmap) library(SummarizedExperiment) # Laad workspace in omdat sommige functies nog wel eens een BiocParallel error gooien (bekend voor het {xcms} package): load(&quot;workspace_eigen_code.RData&quot;) # Maak een variabele met de paden naar de vier te analyseren files: cdfs &lt;- dir(system.file(&quot;cdf&quot;, package = &quot;faahKO&quot;), full.names = TRUE, recursive = TRUE)[c(3, 4, 9, 10)] ## full.names en recursive voor paden i.p.v. bestandsnamen # Maak een phenodata dataframe: pd &lt;- data.frame(sample_name = sub(basename(cdfs), pattern = &quot;.CDF&quot;, replacement = &quot;&quot;, fixed = TRUE), sample_group = c(rep(&quot;KO&quot;, 2), rep(&quot;WT&quot;, 2)), stringsAsFactors = FALSE) ## sub() verwijdert .CDF uit naam, stringsAsFactors = FALSE geeft aan dat er geen factors gemaakt moeten worden van de character vectors pd ## sample_name sample_group ## 1 ko18 KO ## 2 ko19 KO ## 3 wt18 WT ## 4 wt19 WT # Laad de ruwe data: raw_data &lt;- readMSData(files = cdfs, pdata = new(&quot;NAnnotatedDataFrame&quot;, pd), mode = &quot;onDisk&quot;) ## het pdata argument vraagt naar een AnnotatedDataFrame met metadata, onDisk zodat de ruwe data niet opgeslagen wordt in het geheugen (i.v.m. analyse snelheid) Het ‘phenodata’ dataframe functioneert als beschrijving van de experimentele opzet. Voor een echt experiment wordt een tabel aangemaakt met een beschrijving van elk sample. ‘raw_data’ is een ‘OnDiskMSnExp’ object dat per spectrum de gemeten retentie tijden, m/z ratio’s, intensiteiten en total ion currents bevat voor alle monsters (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). 6.3.2 2) Data inspectie Ik begin met het plotten van de base peak chromatograms (BPCs) en total ion chromatograms (TICs) voor elk monster. Een BPC laat een piek zien gebaseerd op het ion met het sterkste signaal. Een TIC laat een piek als som van alle ionen zien. In de ‘chromatogram()’ function staat het ‘aggregationFun’ argument op ‘max’ of ‘sum’ voor respectievelijk een BPC of TIC (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). # Verkrijg BPCs: bpis &lt;- chromatogram(raw_data, aggregationFun = &quot;max&quot;) group_colors &lt;- c(&quot;#60984EA3&quot;, &quot;#604DAF4A&quot;) ## geef KO een paarse kleur en WT een groene kleur. Beide doorzichtig voor plots names(group_colors) &lt;- c(&quot;KO&quot;, &quot;WT&quot;) # bpis bevat de BPCs van alle monsters. Bekijk bijv. de retentie tijden per spectra van één monster met: head(rtime(bpis[1, 1])) ## F1.S0001 F1.S0002 F1.S0003 F1.S0004 F1.S0005 F1.S0006 ## 2501.379 2502.944 2504.509 2506.074 2507.639 2509.204 head(mz(bpis[1, 1])) ## [1] 200 600 head(intensity(bpis[1, 1])) ## F1.S0001 F1.S0002 F1.S0003 F1.S0004 F1.S0005 F1.S0006 ## 145664 145664 145088 147392 152256 158592 # Verkrijg TICs: bpis_2 &lt;- chromatogram(raw_data, aggregationFun = &quot;sum&quot;) # Plot chromatogrammen: plot(bpis, col = group_colors[raw_data$sample_group], main = &quot;BPC per sample: m/z ratio range: 200 - 600&quot;) legend(4100, 1050000, legend = c(&quot;wt&quot;, &quot;ko&quot;), lty = 1, col = c(&quot;#60984EA3&quot;, &quot;#604DAF4A&quot;)) plot(bpis_2, col = group_colors[raw_data$sample_group], main = &quot;TIC per sample: m/z ratio range: 200 - 600&quot;) legend(4100, 2250000, legend = c(&quot;wt&quot;, &quot;ko&quot;), lty = 1, col = c(&quot;#60984EA3&quot;, &quot;#604DAF4A&quot;)) Net als in de vignette kijk ik naar de ion current verdeling per monster om een indruk te krijgen van de kwaliteit van de runs: tc &lt;- split(tic(raw_data), f = fromFile(raw_data)) ## file splitsen op total ion currents per monster boxplot(tc, col = group_colors[raw_data$sample_group], main = &quot;Total ion current per sample&quot;, names = c(&quot;wt18&quot;, &quot;wt19&quot;, &quot;ko18&quot;, &quot;ko19&quot;)) De verdelingen zien eruit zoals in de vignette. Vervolgens maak ik een heatmap om een overzicht te krijgen van hoe de monsters aan elkaar gerelateerd zijn. Net als in de vignette cluster ik de monsters samen gebaseerd op hun BPCs. # Groepeer intensiteiten in retentie tijd bins tegen variatie effect: bpis_bin &lt;- MSnbase::bin(bpis, binSize = 2) # Bereken de correlatie coëfficiënten gebaseerd op log2-genormaliseerde bins: cormat &lt;- cor(log2(do.call(cbind, lapply(bpis_bin, intensity)))) colnames(cormat) &lt;- rownames(cormat) &lt;- raw_data$sample_name ## zet monsters horizontaal en verticaal cormat ## ko18 ko19 wt18 wt19 ## ko18 1.0000000 0.9660005 0.9629162 0.9651172 ## ko19 0.9660005 1.0000000 0.9437898 0.9815005 ## wt18 0.9629162 0.9437898 1.0000000 0.9608660 ## wt19 0.9651172 0.9815005 0.9608660 1.0000000 # Geef phenodata op voor annotatie in heatmap: ann &lt;- data.frame(group = raw_data$sample_group) rownames(ann) &lt;- raw_data$sample_name ann ## group ## ko18 KO ## ko19 KO ## wt18 WT ## wt19 WT pheatmap(cormat, annotation = ann, annotation_color = list(group = group_colors)) Er lijkt een vrij sterke correlatie te zijn tussen de KO en WT monsters met index 19. Ik ben er niet achter gekomen wat deze indexen precies betekenen, iets met de methode/meetvolgorde. Voor de monsters met index 18 lijkt dit niet het geval. 6.3.3 3) Piekdetectie De peak detection wordt uitgevoerd met het centWave algoritme. Daartoe bepaal ik eerst wat de ‘peakwidth’-waarde moet zijn, door het extracted ion chromatogram (EIC) van één piek te plotten. Een EIC laat het signaal zien van één geselecteerd ion oftewel één m/z ratio (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). rtr &lt;- c(2700, 2900) mzr &lt;- c(334.9, 335.1) ## zelfde als in vignette om de samples te kunnen vergelijken chr_raw &lt;- chromatogram(raw_data, mz = mzr, rt = rtr) plot(chr_raw, col = group_colors[chr_raw$sample_group], main = &quot;m/z ratio range: 334.9 - 335.1&quot;) De piek is maximaal 80 seconden breedt. Net als in de vignette stel ik de ‘peakwidth’ in op ‘20, 80’, wat volgens mij de minimale en maximale piekbreedte moet voorstellen. # Voer peak detection uit op EIC: cwp &lt;- CentWaveParam(peakwidth = c(20, 80), noise = 5000, prefilter = c(6, 5000)) # noise en prefilter om de analyse tijd te verlagen xdata &lt;- findChromPeaks(raw_data, param = cwp) # De gevonden pieken per sample met informatie over m/z ratio&#39;s, retentie tijden en intensiteiten: head(chromPeaks(xdata)) ## mz mzmin mzmax rt rtmin rtmax into intb maxo sn ## CP0001 316 316 316 2517.029 2501.379 2535.808 741708.6 727319.6 27816 47 ## CP0002 333 333 333 2515.464 2501.379 2540.503 960445.7 942106.5 33992 42 ## CP0003 338 338 338 2517.029 2501.379 2540.503 788766.4 758962.1 29288 35 ## CP0004 332 332 332 2517.029 2501.379 2545.198 4870388.0 4768520.5 169280 92 ## CP0005 315 315 315 2515.464 2501.379 2540.503 3714288.6 3634444.9 131136 95 ## CP0006 337 337 337 2517.029 2501.379 2549.893 4356732.5 4216751.1 142720 83 ## sample ## CP0001 1 ## CP0002 1 ## CP0003 1 ## CP0004 1 ## CP0005 1 ## CP0006 1 Met de ‘refineChromPeaks’ function kan de detectie worden verfijnd. Pieken die bijv. niet voldoen aan een bepaalde intensiteit worden verwijderd. Hieronder worden overlappende pieken samengevoegd (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). ## de volgende codes zijn uitgezet met &#39;#&#39; omdat ze BiocParallel errors geven tijdens het builden: #mpp &lt;- MergeNeighboringPeaksParam(expandRt = 4) ## check voor overlap in een rt window van vier seconden rond pieken #xdata_pp &lt;- refineChromPeaks(xdata, mpp) De resultaten van de peak detection kunnen op verschillende manieren worden samengevat: # A) Overzicht van het aantal geïdentificeerde pieken per monster en hun breedtes: summary_fun &lt;- function(z) c(peak_count = nrow(z), rt = quantile(z[, &quot;rtmax&quot;] - z[, &quot;rtmin&quot;])) ## voor elk monster T &lt;- lapply(split.data.frame( chromPeaks(xdata_pp), f = chromPeaks(xdata_pp)[, &quot;sample&quot;]), FUN = summary_fun) T ## $`1` ## peak_count rt.0% rt.25% rt.50% rt.75% rt.100% ## 339.000 10.954 34.429 45.383 57.904 173.709 ## ## $`2` ## peak_count rt.0% rt.25% rt.50% rt.75% rt.100% ## 247.0000 10.9540 40.6885 50.0790 64.1630 406.8880 ## ## $`3` ## peak_count rt.0% rt.25% rt.50% rt.75% rt.100% ## 302.000 3.130 35.994 49.296 61.033 424.103 ## ## $`4` ## peak_count rt.0% rt.25% rt.50% rt.75% rt.100% ## 238.000 10.954 39.124 50.078 62.598 593.118 T &lt;- do.call(rbind, T) rownames(T) &lt;- basename(fileNames(xdata_pp)) kbl(T, caption = &quot;__Summary statistics on identified chromatographic peaks__. Shown are the number of identified peaks per sample and their widths/duration.&quot;) %&gt;% kable_styling(full_width = FALSE, bootstrap_options = &quot;striped&quot;, position = &quot;left&quot;, latex_options = &quot;scale_down&quot;) %&gt;% column_spec(1, bold = TRUE) Table 6.3: Summary statistics on identified chromatographic peaks. Shown are the number of identified peaks per sample and their widths/duration. peak_count rt.0% rt.25% rt.50% rt.75% rt.100% ko18.CDF 339 10.954 34.4290 45.383 57.904 173.709 ko19.CDF 247 10.954 40.6885 50.079 64.163 406.888 wt18.CDF 302 3.130 35.9940 49.296 61.033 424.103 wt19.CDF 238 10.954 39.1240 50.078 62.598 593.118 # B) Per monster de &#39;locatie&#39; van pieken in de m/z ratio - retentie tijd dimensie: plotChromPeaks(xdata_pp, file = 1) plotChromPeaks(xdata_pp, file = 3) # C) Piekdichtheid, oftewel het aantal pieken, over de retentie tijd: plotChromPeakImage(xdata_pp) ## lichter van kleur = hogere dichtheid Intermezzo: ontleding van samenvattende tabel ‘split.data.frame(chromPeaks(xdata_pp), f = chromPeaks(xdata_pp)[, “sample”])’ maakt één list van per monster één vector met de geïdentificeerde pieken. Met ‘lapply()’ wordt op elke vector in deze list de ‘summary_fun’ function uitgevoerd, die het aantal pieken en de quantielen van de retentie tijd verdeling teruggeeft. Deze worden opgeslagen als list ‘T’ en ‘do.call()’ roept vervolgens de function ‘rbind’ aan, die de pieken en quantielen combineert in een array. De rijnamen worden vervangen en er wordt een tabel gemaakt. Ik controleer net als in de vignette de piekdetectie met de piek die hierboven is gebruikt om de ‘peakwidth’ te bepalen: # Nogmaals de voorbeeldpiek: plot(chr_raw, col = group_colors[chr_raw$sample_group], main = &quot;m/z ratio range: 334.9 - 335.1&quot;) # Maak het EIC opnieuw, ditmaal bevat het ook de geïdentificeerde pieken van het ion: chr_ex &lt;- chromatogram(xdata_pp, mz = mzr, rt = rtr) sample_colors &lt;- group_colors[chr_ex$sample_group] plot(chr_ex, col = group_colors[chr_raw$sample_group], lwd = 2, peakBg = sample_colors[chromPeaks(chr_ex)[, &quot;sample&quot;]], main = &quot;m/z ratio range: 334.9 - 335.1&quot;) ## highlight de geïdentificeerde pieken # Verkrijg info over de pieken in deze regio: kbl(chromPeaks(xdata_pp, mz = mzr, rt = rtr), caption = &quot;__Identified chromatographic peaks in a selected m/z and retention time range__.&quot;) %&gt;% kable_styling(full_width = FALSE, bootstrap_options = &quot;striped&quot;, position = &quot;left&quot;, latex_options = &quot;scale_down&quot;) %&gt;% column_spec(1, bold = TRUE) Table 6.4: Identified chromatographic peaks in a selected m/z and retention time range. mz mzmin mzmax rt rtmin rtmax into intb maxo sn sample CP0041 335 335 335 2786.201 2764.291 2812.805 211297.2 194283.0 8158 15 1 CP0403 335 335 335 2783.069 2762.725 2812.804 285228.1 264248.6 9154 18 2 CP0718 335 335 335 2787.765 2765.855 2820.629 1636669.0 1603950.7 54640 78 3 CP1060 335 335 335 2784.635 2759.595 2809.674 643673.2 631119.1 20672 54 4 Ik rond de piekdetectie af door te kijken naar de distributie van piek intensiteit per monster. Hiermee controleren ik volgens de vignette of er geen stelselmatige verschillen zijn tussen de runs van de monsters (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). # Verkrijg piek intensiteiten per monster op een log2-schaal: ints &lt;- split(log2(chromPeaks(xdata_pp)[, &quot;into&quot;]), f = chromPeaks(xdata_pp)[, &quot;sample&quot;]) boxplot(ints, varwidth = TRUE, col = group_colors[xdata_pp$sample_group], ylab = expression(log[2]~intensity), main = &quot;Peak intensities per sample&quot;, names = c(&quot;wt18&quot;, &quot;wt19&quot;, &quot;ko18&quot;, &quot;ko19&quot;)) grid(nx = NA, ny = NULL) 6.3.4 4) Alignment De retentie tijd van eenzelfde ion kan variëren tussen monsters (zie EIC voorbeeldpiek). Ik corrigeer hiervoor met de ‘adjustRtime’ function, die de pieken langs de retentie tijd as verschuift om ze te alignen. Hieronder wordt de obiwarp methode gebruikt die de retentie tijden van de spectra alignt, beter bekend als warping (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). # Align: xdata_adj &lt;- adjustRtime(xdata_pp, param = ObiwarpParam(binSize = 0.6)) #Vergelijk retentie tijden: head(rtime(xdata_adj, adjusted = FALSE)) ## F1.S0001 F1.S0002 F1.S0003 F1.S0004 F1.S0005 F1.S0006 ## 2501.379 2502.944 2504.509 2506.074 2507.639 2509.204 head(rtime(xdata_adj)) ## F1.S0001 F1.S0002 F1.S0003 F1.S0004 F1.S0005 F1.S0006 ## 2501.378 2502.971 2504.564 2506.156 2507.748 2509.340 # BPCs vóór alignment: plot(bpis, col = group_colors[raw_data$sample_group], main = &quot;BPC per sample: m/z ratio range: 200 - 600&quot;) legend(4100, 1050000, legend = c(&quot;wt&quot;, &quot;ko&quot;), lty = 1, col = c(&quot;#60984EA3&quot;, &quot;#604DAF4A&quot;)) # BPCs ná alignment: ## de volgende function geeft in deze context BiocParallel errors tijdens het builden: #bpis_adj &lt;- chromatogram(xdata_adj, aggregationFun = &quot;max&quot;, include = &quot;none&quot;) plot(bpis_adj, col = group_colors[bpis_adj$sample_group], main = &quot;BPC per sample after alignment: m/z ratio range: 200 - 600&quot;) legend(4100, 1050000, legend = c(&quot;wt&quot;, &quot;ko&quot;), lty = 1, col = c(&quot;#60984EA3&quot;, &quot;#604DAF4A&quot;)) # Plot ook het verschil tussen de ruwe en aangepaste retentie tijden: plotAdjustedRtime(xdata_adj, col = group_colors[xdata_adj$sample_group]) Het effect van de alignment is goed zichtbaar op de voorbeeldpiek: # Nogmaals de ruwe EIC voorbeeldpiek: plot(chr_raw, col = group_colors[chr_raw$sample_group], main = &quot;m/z ratio range: 334.9 - 335.1&quot;) # Verkrijg het EIC van de voorbeeldpiek na retentie tijd correctie: chr_adj &lt;- chromatogram(xdata_adj, rt = rtr, mz = mzr) plot(chr_adj, col = group_colors[chr_raw$sample_group], peakType = &quot;none&quot;, main = &quot;m/z ratio range: 334.9 - 335.1&quot;) 6.3.5 5) Correspondence De laatste preprocessing-stap is het identificeren van dezelfde pieken in de monsters: de correspondence analysis. Daartoe worden de pieken eerst per kleine m/z ratio-intervallen gegroepeerd in features op basis van de piekdichtheid over de retenie tijd. Hieronder een voorbeeld voor het m/z ratio interval 305.05 - 305.15 (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). # Defineer interval: mzr &lt;- c(305.05, 305.15) # Verkrijg bijbehorend EIC: ## deze function geeft BiocParallel errors tijdens het builden: #chr_mzr &lt;- chromatogram(xdata_adj, mz = mzr) # Groepeer pieken: pdp &lt;- PeakDensityParam(sampleGroups = xdata_adj$sample_group, minFraction = 0.4, bw = 30) ## &#39;minFraction = 0.4&#39; geeft aan dat alleen pieken gegroepeerd worden die in minstens 40% van de monsters voorkomen, &#39;bw = 30&#39; geeft de SD van de Kernel lijnsmoothing methode # Plot resultaat: plotChromPeakDensity(chr_mzr, col = sample_colors, param = pdp, peakBg = sample_colors[chromPeaks(chr_mzr)[, &quot;sample&quot;]], peakCol = sample_colors[chromPeaks(chr_mzr)[, &quot;sample&quot;]], peakPch = 16, main = &quot;m/z ratio range: 305.05 - 305.15&quot;) Het bovenste paneel highlight de pieken in de EICs van de monsters. Het onderste paneel laat zien welke monsters (y-as) bij een bepaalde retentie tijd een piek lieten zien. Zo laten alle vier de monsters een piek zijn bij retentie tijden van ~ 2900 en 3500 seconden. Ik definieer nu volgens de vignette de features van de gehele dataset en voer hier de correspondence analysis op uit met de ‘groupChromPeaks’ function: pdp &lt;- PeakDensityParam(sampleGroups = xdata_adj$sample_group, minFraction = 0.4, bw = 30) xdata_cor &lt;- groupChromPeaks(xdata_adj, param = pdp) De resultaten van de preprocessing worden met de ‘quantify’ function samengevat tot een ‘SummarizedExperiment’ object: res &lt;- quantify(xdata_cor) # Informatie over de monsters: colData(res) ## DataFrame with 4 rows and 2 columns ## sample_name sample_group ## &lt;character&gt; &lt;character&gt; ## ko18.CDF ko18 KO ## ko19.CDF ko19 KO ## wt18.CDF wt18 WT ## wt19.CDF wt19 WT # Informatie over de features: featureDefinitions(xdata_cor) ## DataFrame with 466 rows and 11 columns ## mzmed mzmin mzmax rtmed rtmin rtmax npeaks ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## FT001 205.00 205.0 205.0 2786.11 2783.61 2788.05 4 ## FT002 206.00 206.0 206.0 2785.11 2784.97 2787.60 3 ## FT003 207.10 207.1 207.1 2712.81 2711.68 2713.95 2 ## FT004 233.05 233.0 233.1 3017.70 3012.26 3023.14 2 ## FT005 241.10 241.1 241.1 3678.22 3672.32 3688.44 3 ## ... ... ... ... ... ... ... ... ## FT462 594.20 594.2 594.2 3392.98 3392.98 3392.98 1 ## FT463 594.35 594.3 594.4 3615.25 3613.90 3616.60 2 ## FT464 595.20 595.2 595.2 2999.10 2999.10 2999.10 1 ## FT465 596.35 596.3 596.4 3811.98 3808.11 3816.29 4 ## FT466 597.40 597.4 597.4 3813.65 3813.65 3813.65 1 ## KO WT peakidx ms_level ## &lt;numeric&gt; &lt;numeric&gt; &lt;list&gt; &lt;integer&gt; ## FT001 2 2 43,366,637,... 1 ## FT002 1 2 30,620,912 1 ## FT003 1 1 19,604 1 ## FT004 1 0 67,71 1 ## FT005 2 1 258, 518,1085 1 ## ... ... ... ... ... ## FT462 0 1 716 1 ## FT463 1 1 218,780 1 ## FT464 0 1 654 1 ## FT465 2 2 281,550,830,... 1 ## FT466 0 1 831 1 # Per monster per feature de som van de intensiteiten van de feature pieken: head(featureValues(xdata_cor)) ## ko18.CDF ko19.CDF wt18.CDF wt19.CDF ## FT001 1714581.8 1220358.1 1810112.3 1507943.1 ## FT002 194603.7 NA 228501.1 216393.1 ## FT003 337473.3 NA 182162.0 NA ## FT004 209999.6 NA NA NA ## FT005 1345515.1 608016.5 NA 621437.9 ## FT006 NA NA NA 214367.8 Indien er voor een monster geen pieken van een bepaalde feature zijn gevonden, zien we ‘NA’. Missende intensiteiten worden ingevuld gebaseerd op de intensiteit van het feature in de andere monsters. De m/z ratio interval - retentie tijd regio van een feature wordt daartoe bepaald met de ‘ChromPeakAreaParam()’ function: de onderste grenzen van m/z ratio en retentie tijd zijn gelijk aan de 25% quantielen van respectievelijk de laagste m/z ratio (‘mzmin’) en de laagste retentie tijd (‘rtmin’) van alle pieken. De bovenste grenzen zijn gelijk aan de 75% quantielen van de hoogste m/z ratio (‘mzmax’) en de hoogste retentie tijd (‘rtmax’) (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). xdata_fill &lt;- fillChromPeaks(xdata_cor, param = ChromPeakAreaParam()) head(featureValues(xdata_fill)) ## ko18.CDF ko19.CDF wt18.CDF wt19.CDF ## FT001 1714581.8 1220358.09 1810112.3 1507943.1 ## FT002 194603.7 148572.79 228501.1 216393.1 ## FT003 337473.3 102700.34 182162.0 165815.6 ## FT004 209999.6 269525.70 278783.0 178828.5 ## FT005 1345515.1 608016.51 743080.2 621437.9 ## FT006 NA 34687.66 NA 214367.8 # NA&#39;s vóór invullen: apply(featureValues(xdata_fill, filled = FALSE), MARGIN = 2, FUN = function(z) sum(is.na(z))) # &#39;MARGIN = 2&#39; geeft aan dat de functie wordt toegepast op de kolommen van &#39;xdata_fill&#39; ## ko18.CDF ko19.CDF wt18.CDF wt19.CDF ## 140 226 182 239 # NA&#39;s ná invullen: apply(featureValues(xdata_fill), MARGIN = 2, FUN = function(z) sum(is.na(z))) ## ko18.CDF ko19.CDF wt18.CDF wt19.CDF ## 22 28 26 40 Als volgt gebruik ik de ‘featureSummary’ function voor een algemene samenvatting per feature. ‘count’ en ‘perc’ geven het aantal monsters aan waarin een feature is gevonden. ‘multi_count’ en ‘multi_perc’ geven het aantal monsters aan waarin meer dan één piek uit een feature is teruggevonden. Het ‘group’ argument verdeelt deze statistieken verder over knock-out en wildtype monsters (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). head(featureSummary(xdata_fill, group = xdata_fill$sample_group)) ## count perc multi_count multi_perc rsd KO_count KO_perc ## FT001 4 100 0 0 0.16700614 2 100 ## FT002 3 75 0 0 0.08058298 1 50 ## FT003 2 50 0 0 0.42268744 1 50 ## FT004 1 25 1 100 NA 1 50 ## FT005 3 75 0 0 0.49162595 2 100 ## FT006 1 25 0 0 NA 0 0 ## KO_multi_count KO_multi_perc KO_rsd WT_count WT_perc WT_multi_count ## FT001 0 0 0.2381438 2 100 0 ## FT002 0 0 NA 2 100 0 ## FT003 0 0 NA 1 50 0 ## FT004 1 100 NA 0 0 0 ## FT005 0 0 0.5338948 1 50 0 ## FT006 0 0 NA 1 50 0 ## WT_multi_perc WT_rsd ## FT001 0 0.12878983 ## FT002 0 0.03848858 ## FT003 0 NA ## FT004 0 NA ## FT005 0 NA ## FT006 0 NA # Voeg de samenvatting met ingevulde pieken toe aan &#39;res&#39;: assays(res)$raw_filled &lt;- featureValues(xdata_fill, filled = TRUE) head(assay(res, &quot;raw&quot;)) ## ko18.CDF ko19.CDF wt18.CDF wt19.CDF ## FT001 1714581.8 1220358.1 1810112.3 1507943.1 ## FT002 194603.7 NA 228501.1 216393.1 ## FT003 337473.3 NA 182162.0 NA ## FT004 209999.6 NA NA NA ## FT005 1345515.1 608016.5 NA 621437.9 ## FT006 NA NA NA 214367.8 head(assay(res, &quot;raw_filled&quot;)) ## ko18.CDF ko19.CDF wt18.CDF wt19.CDF ## FT001 1714581.8 1220358.09 1810112.3 1507943.1 ## FT002 194603.7 148572.79 228501.1 216393.1 ## FT003 337473.3 102700.34 182162.0 165815.6 ## FT004 209999.6 269525.70 278783.0 178828.5 ## FT005 1345515.1 608016.51 743080.2 621437.9 ## FT006 NA 34687.66 NA 214367.8 Met de ‘featureChromatograms’ function kan voor elke feature een EIC gemaakt worden (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). Er zijn in totaal 268 features (‘nrow(featureValues(xdata_fill, filled = TRUE))’), ik laat de pieken van de eerste vier zien: feature_chroms &lt;- featureChromatograms(xdata_fill, features = 1:4) # EIC informatie eerste vier features: chromPeaks(feature_chroms[1:4, ]) ## mz mzmin mzmax rt rtmin rtmax into intb maxo ## CP0053 205.0 205.0 205.0 2788.052 2766.480 2818.842 1714581.8 1643169.4 63800 ## CP0407 205.0 205.0 205.0 2786.199 2762.725 2817.498 1220358.1 1164812.1 39104 ## CP0719 205.0 205.0 205.0 2783.610 2762.676 2813.673 1810112.3 1740802.4 63200 ## CP1063 205.0 205.0 205.0 2786.022 2763.892 2820.934 1507943.1 1445439.2 49144 ## CP0035 206.0 206.0 206.0 2784.971 2768.022 2815.764 194603.7 182508.9 8483 ## CP0701 206.0 206.0 206.0 2785.107 2764.170 2812.162 228501.1 212686.2 8450 ## CP1051 206.0 206.0 206.0 2787.605 2762.315 2814.578 216393.1 202836.7 7652 ## CP0020 207.1 207.1 207.1 2713.948 2701.542 2743.337 337473.3 335177.5 14035 ## CP0682 207.1 207.1 207.1 2711.681 2693.470 2725.244 182162.0 165026.9 10354 ## CP0078 233.1 233.1 233.1 3012.260 2998.279 3043.347 209999.6 196015.1 21048 ## CP0082 233.0 233.0 233.0 3023.137 2964.127 3066.682 364299.5 313862.2 21352 ## sn sample row column ## CP0053 37 1 1 1 ## CP0407 33 2 1 2 ## CP0719 42 3 1 3 ## CP1063 40 4 1 4 ## CP0035 17 1 2 1 ## CP0701 12 3 2 3 ## CP1051 19 4 2 4 ## CP0020 47 1 3 1 ## CP0682 13 3 3 3 ## CP0078 14 1 4 1 ## CP0082 24 1 4 1 # EICs: plot(feature_chroms, col = sample_colors, peakBg = sample_colors[chromPeaks(feature_chroms)[, &quot;sample&quot;]]) Ik rond de analyse af met een principal component analysis, waarmee wordt bepaald hoe de monsters in dit experiment zich tot elkaar verhouden. Er is geen data normalisatie stap beschikbaar binnen het {xcms} package. # Log2-transformeer de features: ft_ints &lt;- log2(assay(res, &quot;raw_filled&quot;)) # Voer de PCA uit: pc &lt;- prcomp(t(na.omit(ft_ints)), center = TRUE) ## negeer missende waarden met &#39;na.omit()&#39; en trek de gemiddelde intensiteit van alle intensiteiten af met &#39;center = TRUE&#39; summary(pc) ## Importance of components: ## PC1 PC2 PC3 PC4 ## Standard deviation 15.3020 13.8276 7.5980 2.388e-14 ## Proportion of Variance 0.4847 0.3958 0.1195 0.000e+00 ## Cumulative Proportion 0.4847 0.8805 1.0000 1.000e+00 # Plot de PCA resultaten: cols &lt;- group_colors[xdata_fill$sample_group] pcSummary &lt;- summary(pc) plot(pc$x[, 1], pc$x[,2], pch = 21, main = &quot;&quot;, xlab = paste0(&quot;PC1: &quot;, format(pcSummary$importance[2, 1] * 100, digits = 3), &quot; % variance&quot;), ylab = paste0(&quot;PC2: &quot;, format(pcSummary$importance[2, 2] * 100, digits = 3), &quot; % variance&quot;), col = &quot;darkgrey&quot;, bg = cols, cex = 2) grid() text(pc$x[, 1], pc$x[,2], labels = xdata_fill$sample_name, col = &quot;darkgrey&quot;, pos = c(4, 3, 1, 2), cex = 1) Conclusie Volgens PC1, wat 48,5% van de variatie omvat, is er een duidelijk verschil tussen de monsters gebaseerd op aanwezigheid van het werkzame FAAH gen. Volgens PC2, met 39,6% variatie ook een aanzienlijk signaal, worden de monsters ook verdeeld gebaseerd op hun index. Omdat er niet van te voren genormaliseerd is, zou dit verschil veroorzaakt kunnen worden door een afwijking in de methode. Bijvoorbeeld: de dag waarop is gemeten heeft het resultaat beïnvloedt (“LCMS Data Preprocessing and Analysis with Xcms” n.d.). 6.4 Afronding Wat hebben de afgelopen 32 uur mij gebracht? Het meest heb ik opgestoken van de hindernissen die ik tegenkwam tijdens de installatie van nieuwe R packages. Van een verouderde RTools versie tot missende function beschrijvingen en errors in een package zelf. Ik vind het waardevol om alle stappen, van het bedenken wat voor een package je nodig hebt tot je eigen analyse schrijven, doorlopen te hebben. Daarnaast heb ik geleerd wat voor preprocessing stappen er nodig zijn om van ruwe MS data te komen tot een vergelijking van samenstellingen tussen monsters. Ik verwacht niet dat mijn ervaring met het {xcms} package mij direct gaat helpen tijdens mijn stage of werk; wanneer ik met een massaspectrometer ga werken verwacht ik dat de metingen geanalyseerd worden in een speciaal programma dat geen aanvulling nodig heeft van een dergelijk package. Desalniettemin verwacht ik wél dat ik nu beter kan inschatten en begrijpen wat er achter de schermen van zo’n programma allemaal moet gebeuren. Daarnaast zou ik met behulp van dit package mijn ruwe data en gebruikte analyse wel openbaar kunnen maken, waarmee ik anderen kan helpen of om hulp en feedback kan vragen. De komende tijd zal ik verder werken aan mijn skill door te oefenen met andere R packages, zoals {ptw}. Ik hoop daarmee mijn algemene begrip van MS data, preprocessing en analyses te vergroten. Op school zijn een aantal mooie massaspectrometers aanwezig. Ik heb al een keer een introductie van een docent gekregen op een UPLC-MS en zal ook zeker om een vervolg vragen. Daarbij zal ik Chemie docenten en studenten vragen hoe zij de MS data precies analyseren en me gaan verdiepen in de door hun gebruikte programma’s. Ik weet zeker dat ik daarmee goed voorbereid ben op mijn droomstage en een bedrijf zelfs kan helpen in de richting van een betere analyse workflow. "],["vaardigheid-5-correct-refereren-m.b.v.-een-reference-manager.html", "7 Vaardigheid 5: Correct refereren m.b.v. een reference manager 7.1 DSFB2 2022 Project Regenwormen: Introductie", " 7 Vaardigheid 5: Correct refereren m.b.v. een reference manager Parallel aan de Workflows lessen van Data Sciences for Biology 2 heb ik samen met twee medestudenten een project uitgevoerd. Hieronder laat ik met een introductie op dit project zien, dat ik de reference manager Zotero kan gebruiken om te parafraseren. 7.1 DSFB2 2022 Project Regenwormen: Introductie Oud-student aan Hogeschool Utrecht Jory van Thiel heeft, samen met instituten in Leiden en Liverpool, onderzoek gedaan naar de convergente evolutie van het defensieve gif van spugende cobras. Drie cobra soorten hebben convergent, of te wel onafhankelijk van elkaar, het vermogen ontwikkeld om gif te spugen ter verdediging, in tegen stelling tot andere cobras die gif inspuiten in een prooi. Jory en de andere onderoekers hebben laten zien dat het gif van spugende soorten wordt gekarakteriseerd door een significante upregulatie in fosfolipase A2, wat de activatie van sensorische zoogdier neuronen door cytotoxines in het gif stimuleert. Dit veroorzaakt meer pijn in, bijvoorbeeld, de ogen van een roofdier dan gif van bijtende cobras zal doen (Kazandjian et al. 2021). BMR projecticum studenten zijn afgelopen jaar door Jory gevraagd om te onderzoeken wat het effect is van fosfolipase A2 op skeletspiercellen. Hogeschool Utrecht docenten Ronald Vlasblom en Robert Jan Veldman keken daarnaast naar het effect van fosfolipase A2 op ratten hartjes in een Langendorff opstelling. In een dergelijke opstelling worden de hartjes via de aorta retrograde geperfundeerd met een zuurstof- en voedingsrijke oplossing. De omgekeerde vloeistofdruk, van aorta naar linker hartkamer, zorgt ervoor dat de aorta kleppen sluiten en de vloeistof naar de kransslagaders wordt gedwongen. Dit voedt de hartspier, die hierdoor enkele uren buiten de rat kan blijven kloppen (Broadley 1979). Ronald en Robert Jan lieten zien dat na toevoeging van 40 µg gif van de spugende cobra Naja pallida snel een verstoord hartritme en zelfs een hartstilstand volgde (“Project Regenwormen: Data Sciences for Biology 2” n.d.). De Universiteit van Liverpool wil deze observaties graag gebruiken binnen hun onderzoek naar de acute myotoxiciteit van slangengif en de ontwikkeling van blokkers om dit effect te ondervangen. Op dit moment helpen studenten onder leiding van Ronald met het ontwikkelen van proefdiervrije onderzoeksmodellen voor deze onderzoeksvragen. Dat wil hier zeggen: modellen waarbij geen gebruik wordt gemaakt van ratten hartjes. Ronald en Robert Jan lieten zien dat defensief gif een zelfde effect heeft op de contractiekracht en -frequentie van het gladde spierweefsel van de crop-gizzard van een regenworm (“Project Regenwormen: Data Sciences for Biology 2” n.d.). De crop-gizzard wordt uit een regenworm geïsoleerd en in een orgaanbad van Ringer buffer aan een verplaatsingsmeter gehangen. In de buffer blijft het spierweefsel enige tijd functioneel. Als het contracteert, verplaatst het de hefboom van de verplaatsingsmeter. Hoe sterker of vaker het weefsel contracteert, hoe sterker of vaker de hefboom verplaatst. Deze verplaatsingen worden geregistreerd als veranderingen in spanning over tijd en komen op de laptop van Ronald en de studenten binnen in het programma LabChart (“Project Regenwormen: Data Sciences for Biology 2” n.d.; “Thema 3: Regenworm: DOFAR Dierkundig Onderzoek” n.d.). Om het effect van een giftoediening te bepalen, worden veranderingen in contractiekracht en -frequentie met het oog opgepikt uit de tracings in LabChart. Dit is tijdsintensief en gevoelig voor fouten. Daarom heeft Ronald mij en twee medestudenten gevraagd om een automatische analyse voor de tracings te coderen. De komende weken tot de zomervakantie zullen wij proberen om voor Ronald en zijn studenten een interactieve Shiny app te bouwen die, voor gedefinieerde tijdsvensters van interesse, met behulp van grafieken de kracht en duur van elke contractie laat zien evenals de time to contraction, time to relaxation en contractie frequentie. "],["vaardigheid-6-werken-met-relational-databases.html", "8 Vaardigheid 6: Werken met relational databases 8.1 Samenvoegen van virus-activiteit dummy data met gapminder dataset", " 8 Vaardigheid 6: Werken met relational databases Tijdens een data analyse wordt vaak de informatie uit verschillende databases gecombineerd. Een gemeenschappelijk gebruikte taal voor het ophalen, beheren en opslaan van data uit gerelateerde databases is SQL. In dergelijke databases is data georganiseerd in tabellen die aan elkaar gekoppeld kunnen worden gebaseerd op gemeenschappelijke eigenschappen. Met het onderstaande voorbeeld laat ik zien, dat ik met SQL de informatie uit drie verschillende tabellen in DBeaver kan samenvoegen. 8.1 Samenvoegen van virus-activiteit dummy data met gapminder dataset Ik maak eerst drie tabellen aan in RStudio: één met de gapminder dataset van het {dslabs} package en twee tabellen met datasets waarin voor verschillende landen de Influenza of Knokkelkoorts activiteit meerdere keren per jaar gemeten is. #Tabel 1: gapminder_df &lt;- as.data.frame(gapminder) head(gapminder_df, 3) ## country year infant_mortality life_expectancy fertility population ## 1 Albania 1960 115.4 62.87 6.19 1636054 ## 2 Algeria 1960 148.2 47.50 7.65 11124892 ## 3 Angola 1960 208.0 35.98 7.32 5270844 ## gdp continent region ## 1 NA Europe Southern Europe ## 2 13828152297 Africa Northern Africa ## 3 NA Africa Middle Africa #Tabel 2: flu_df &lt;- as.data.frame(read.csv(here::here(&quot;data_raw&quot;, &quot;data03_assignment_7&quot;, &quot;flu_data.csv&quot;), skip = 11)) head(flu_df, 3) ## Date Argentina Australia Austria Belgium Bolivia Brazil Bulgaria Canada ## 1 2002-12-29 NA NA NA NA NA 174 NA NA ## 2 2003-01-05 NA NA NA NA NA 162 NA NA ## 3 2003-01-12 NA NA NA NA NA 174 NA NA ## Chile France Germany Hungary Japan Mexico Netherlands New.Zealand Norway ## 1 NA NA NA NA NA NA NA NA NA ## 2 NA NA NA NA NA NA NA NA NA ## 3 1 NA NA NA NA NA NA NA NA ## Paraguay Peru Poland Romania Russia South.Africa Spain Sweden Switzerland ## 1 NA 329 NA NA NA NA NA NA NA ## 2 NA 315 NA NA NA NA NA NA NA ## 3 NA 314 NA NA NA NA NA NA NA ## Ukraine United.States Uruguay ## 1 NA NA NA ## 2 NA NA NA ## 3 NA NA NA #Tabel 3: dengue_df &lt;- as.data.frame(read.csv(here::here(&quot;data_raw&quot;, &quot;data03_assignment_7&quot;, &quot;dengue_data.csv&quot;), skip = 11)) head(dengue_df, 3) ## Date Argentina Bolivia Brazil India Indonesia Mexico Philippines ## 1 2002-12-29 NA 0.101 0.073 0.062 0.101 NA NA ## 2 2003-01-05 NA 0.143 0.098 0.047 0.039 NA NA ## 3 2003-01-12 NA 0.176 0.119 0.051 0.059 0.071 NA ## Singapore Thailand Venezuela ## 1 0.059 NA NA ## 2 0.059 NA NA ## 3 0.238 NA NA De Influenza en Knokkelkoorts data is niet tidy. Ik maak de tabellen zelf tidy met: flu_df &lt;- pivot_longer(data = flu_df, cols=c(2:30), names_to = &quot;country&quot;, values_to = &quot;influenza_activity&quot;) dengue_df &lt;- pivot_longer(data = dengue_df, cols=c(2:11), names_to = &quot;country&quot;, values_to = &quot;dengue_activity&quot;) Voordat ik de tabellen ga samenvoegen in DBeaver, zorg ik er eerst voor dat de variabelen waarop ik de tabellen wil samenvoegen, land en datum, hetzelfde zijn. In de gapminder tabel is de datum aanwezig als jaartallen in een kolom ‘year’, In de andere tabellen is de datum aanwezig als jaar-maand-dag in een kolom ‘Date.’ Tevens is het belangrijk dat de land en datum kolommen dezelfde titel hebben en van hetzelfde datatype zijn. # Zorg dat er in de Influenza en Knokkelkoorts tabel een kolom aanwezig is met de jaartallen, net als in de gapminder tabel: flu_df &lt;- separate(data = flu_df, col = Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) dengue_df &lt;- separate(data = dengue_df, col = Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) # Maak nieuwe tabellen, met de Influenza of Knokkelkoorts activiteit per jaar i.p.v. per dag: flu_df &lt;- flu_df %&gt;% group_by(country, year) %&gt;% summarise_each(funs(sum), influenza_activity) dengue_df &lt;- dengue_df %&gt;% group_by(country, year) %&gt;% summarise_each(funs(sum), dengue_activity) ## Afgekeken van https://stackoverflow.com/questions/25089665/error-only-defined-on-a-data-frame-with-all-numeric-variables-with-ddply-on-lar # Maak in deze tabellen de kolommen waarop wordt samengevoegd van hetzelfde datatype als in de gapminder tabel: flu_df$country &lt;- as.factor(flu_df$country) dengue_df$country &lt;- as.factor(dengue_df$country) flu_df$year &lt;- as.integer(flu_df$year) dengue_df$year &lt;- as.integer(dengue_df$year) # Maak opnieuw dataframes van de tabellen: flu_df &lt;- as.data.frame(flu_df) dengue_df &lt;- as.data.frame(dengue_df) # Sla drie dataframes op als CSV en RDS files: #write.csv(gapminder_df, file = &quot;gapminder_df.csv&quot;) #write.csv(flu_df, file = &quot;flu_df.csv&quot;) #write.csv(dengue_df, file = &quot;dengue_df.csv&quot;) #saveRDS(gapminder_df, &quot;C:/Users/steph/DSFB2/portfolio_book/gapminder_df.rds&quot;) #saveRDS(flu_df, &quot;C:/Users/steph/DSFB2/portfolio_book/flu_df.rds&quot;) #saveRDS(dengue_df, &quot;C:/Users/steph/DSFB2/portfolio_book/dengue_df.rds&quot;) De kolommen met land en datum zijn nu hetzelfde en de tabellen kunnen geüpload worden naar DBeaver: library(DBI) # Maak verbinding met mijn database in DBeaver: con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;...&quot;) # Stuur de tabellen naar de database: dbWriteTable(con, &quot;flu_df&quot;, flu_df) dbWriteTable(con, &quot;dengue_df&quot;, dengue_df) dbWriteTable(con, &quot;gapminder_df&quot;, gapminder_df) # Sluit de verbinding weer: dbDisconnect(con) Om de data(overdracht) te inspecteren, heb ik in DBeaver de ‘Data’, ‘Properties’ en ‘ER Diagram’ tabs van de tabellen bekeken. Daarnaast heb ik de volgende SQL queries uitgevoerd, waarmee ik specifieke data uit de tabellen opvraag en controleer of dit correct werkt: Deze queries gaven de verwachtte output. Ze zijn vertaald naar een zelfde inspectie in R: str(dengue_df) ## &#39;data.frame&#39;: 140 obs. of 3 variables: ## $ country : Factor w/ 10 levels &quot;Argentina&quot;,&quot;Bolivia&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ year : int 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 ... ## $ dengue_activity: num NA NA 1.53 1.03 1.01 ... str(flu_df) ## &#39;data.frame&#39;: 406 obs. of 3 variables: ## $ country : Factor w/ 29 levels &quot;Argentina&quot;,&quot;Australia&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ year : int 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 ... ## $ influenza_activity: int NA NA 8843 8627 8966 10267 9299 7952 6946 5541 ... str(gapminder_df) ## &#39;data.frame&#39;: 10545 obs. of 9 variables: ## $ country : Factor w/ 185 levels &quot;Albania&quot;,&quot;Algeria&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... ## $ year : int 1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ... ## $ infant_mortality: num 115.4 148.2 208 NA 59.9 ... ## $ life_expectancy : num 62.9 47.5 36 63 65.4 ... ## $ fertility : num 6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ... ## $ population : num 1636054 11124892 5270844 54681 20619075 ... ## $ gdp : num NA 1.38e+10 NA NA 1.08e+11 ... ## $ continent : Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 4 1 1 2 2 3 2 5 4 3 ... ## $ region : Factor w/ 22 levels &quot;Australia and New Zealand&quot;,..: 19 11 10 2 15 21 2 1 22 21 ... # Per land de Influenza activiteit, Knokkelkoorts activiteit en kindersterfte in 2009: head(flu_df %&gt;% filter(year == 2009) %&gt;% select(country, influenza_activity, year)) ## country influenza_activity year ## 1 Argentina 7952 2009 ## 2 Australia 22796 2009 ## 3 Austria 47117 2009 ## 4 Belgium 10320 2009 ## 5 Bolivia 14516 2009 ## 6 Brazil 10984 2009 head(dengue_df %&gt;% filter(year == 2009) %&gt;% select(country, dengue_activity, year)) ## country dengue_activity year ## 1 Argentina 16.739 2009 ## 2 Bolivia 10.362 2009 ## 3 Brazil 8.211 2009 ## 4 India 4.549 2009 ## 5 Indonesia 9.228 2009 ## 6 Mexico 14.228 2009 head(gapminder_df %&gt;% filter(year == 2009) %&gt;% select(country, infant_mortality, year)) ## country infant_mortality year ## 1 Albania 15.4 2009 ## 2 Algeria 24.3 2009 ## 3 Angola 112.2 2009 ## 4 Antigua and Barbuda 8.2 2009 ## 5 Argentina 13.4 2009 ## 6 Armenia 17.0 2009 # De laagst gemeten Influenza activiteit, Knokkelkoorts activiteiten kindersterfte: head(dengue_df %&gt;% select(country, dengue_activity, year) %&gt;% arrange(dengue_activity)) ## country dengue_activity year ## 1 Singapore 0.059 2002 ## 2 India 0.062 2002 ## 3 Brazil 0.073 2002 ## 4 Bolivia 0.101 2002 ## 5 Indonesia 0.101 2002 ## 6 Bolivia 0.427 2015 head(flu_df %&gt;% select(country, influenza_activity, year) %&gt;% arrange(influenza_activity)) ## country influenza_activity year ## 1 Sweden 106 2010 ## 2 Sweden 153 2006 ## 3 Sweden 169 2008 ## 4 Brazil 174 2002 ## 5 Sweden 179 2007 ## 6 Sweden 201 2011 head(gapminder_df %&gt;% select(country, infant_mortality, year) %&gt;% arrange(infant_mortality)) ## country infant_mortality year ## 1 Luxembourg 1.5 2015 ## 2 Luxembourg 1.6 2012 ## 3 Iceland 1.6 2013 ## 4 Luxembourg 1.6 2013 ## 5 Iceland 1.6 2014 ## 6 Luxembourg 1.6 2014 # De jaartallen in de gapminder dataset: gapminder_df %&gt;% select(year) %&gt;% arrange() %&gt;% unique() %&gt;% as.character() ## [1] &quot;1960:2016&quot; De inspectie in R gaf dezelfde, correcte resultaten als de queries. De tabellen kunnen nu samengevoegd worden gebaseerd op de compound key ‘country’ en ‘year’ van de tabellen. Ik doe dit eerst in R…: #readRDS(here::here(&quot;gapminder_df.rds&quot;)) #readRDS(here::here(&quot;flu_df.rds&quot;)) #readRDS(here::here(&quot;dengue_df.rds&quot;)) # Voeg flu_df en dengue_df samen...: flu_dengue &lt;- left_join(flu_df, dengue_df, by = c(&quot;country&quot;, &quot;year&quot;)) #...en voeg gapminder_df toe: flu_dengue_gapminder_R &lt;- left_join(flu_dengue, gapminder_df, by = c(&quot;country&quot;, &quot;year&quot;)) head(flu_dengue_gapminder_R, 5) ## country year influenza_activity dengue_activity infant_mortality ## 1 Argentina 2002 NA NA 17.1 ## 2 Argentina 2003 NA NA 16.6 ## 3 Argentina 2004 8843 1.533 16.0 ## 4 Argentina 2005 8627 1.035 15.3 ## 5 Argentina 2006 8966 1.007 14.6 ## life_expectancy fertility population gdp continent region ## 1 74.3 2.38 37889443 242076212334 Americas South America ## 2 74.5 2.34 38309475 263468585945 Americas South America ## 3 75.0 2.31 38728778 287258675094 Americas South America ## 4 75.3 2.29 39145491 313626005874 Americas South America ## 5 75.3 2.27 39558750 340177780212 Americas South America …en vervolgens in DBeaver: De output tabel van bovenstaande querie is opgeslagen als een CSV bestand (flu_dengue_gapminder.csv) en kan gebruikt worden in R: flu_dengue_gapminder &lt;- read_csv(here::here(&quot;data&quot;, &quot;data01_assignment_7&quot;, &quot;flu_dengue_gapminder.csv&quot;)) # Voorbeeld met eerste 10 rijen: ## Om één of andere reden verhelpt &#39;latex_options = &quot;scale_down&quot;&#39;, afgekeken van https://stackoverflow.com/questions/49044753/scale-kable-table-to-fit-page-width, NIET het buiten de marges vallen van de tabel... kbl(head(flu_dengue_gapminder, 10), caption = &quot;__De gapminder dataset samengevoegd met de Influenza en \\nKnokkelkoorts activiteit data__&quot;) %&gt;% kable_styling(full_width = F, bootstrap_options = &quot;striped&quot;, position = &quot;left&quot;, latex_options = &quot;scale_down&quot;) %&gt;% column_spec(1:5, bold = TRUE) Table 8.1: De gapminder dataset samengevoegd met de Influenza en Knokkelkoorts activiteit data Country Year Influenza_activity Dengue_activity infant_mortality life_expectancy fertility population gdp continent region Argentina 2002 NA NA 17.1 74.3 2.38 37889443 242076212334 Americas South America Argentina 2003 NA NA 16.6 74.5 2.34 38309475 263468585945 Americas South America Argentina 2004 8843 1.533 16.0 75.0 2.31 38728778 287258675094 Americas South America Argentina 2005 8627 1.035 15.3 75.3 2.29 39145491 313626005874 Americas South America Argentina 2006 8966 1.007 14.6 75.3 2.27 39558750 340177780212 Americas South America Argentina 2007 10267 5.569 14.1 75.2 2.25 39969903 369614509411 Americas South America Argentina 2008 9299 1.462 13.7 75.4 2.24 40381860 394594682115 Americas South America Argentina 2009 7952 16.739 13.4 75.6 2.23 40798641 397949689763 Americas South America Argentina 2010 6946 6.621 13.0 75.8 2.22 41222875 434405530244 Americas South America Argentina 2011 5541 3.186 12.7 76.0 2.20 41655616 472935255184 Americas South America summary(flu_dengue_gapminder) ## Country Year Influenza_activity Dengue_activity ## Length:406 Min. :2002 Min. : 106 Min. : 0.073 ## Class :character 1st Qu.:2005 1st Qu.: 3302 1st Qu.: 1.508 ## Mode :character Median :2008 Median : 9214 Median : 4.303 ## Mean :2008 Mean : 23372 Mean : 5.001 ## 3rd Qu.:2012 3rd Qu.: 32278 3rd Qu.: 7.872 ## Max. :2015 Max. :155577 Max. :16.739 ## NA&#39;s :72 NA&#39;s :354 ## infant_mortality life_expectancy fertility population ## Min. : 2.000 Min. :64.70 Min. :1.150 Min. : 3324096 ## 1st Qu.: 3.700 1st Qu.:74.17 1st Qu.:1.420 1st Qu.: 9072979 ## Median : 5.850 Median :78.25 Median :1.755 Median : 20977828 ## Mean : 9.641 Mean :77.20 Mean :1.838 Mean : 42737637 ## 3rd Qu.:13.325 3rd Qu.:80.80 3rd Qu.:1.990 3rd Qu.: 46527412 ## Max. :53.700 Max. :83.20 Max. :3.980 Max. :207847528 ## NA&#39;s :42 NA&#39;s :42 NA&#39;s :42 NA&#39;s :42 ## gdp continent region ## Min. :7.214e+09 Length:406 Length:406 ## 1st Qu.:5.680e+10 Class :character Class :character ## Median :2.616e+11 Mode :character Mode :character ## Mean :5.748e+11 ## 3rd Qu.:6.370e+11 ## Max. :5.218e+12 ## NA&#39;s :146 Tijd om de daadwerkelijke data te gaan analyseren. Ik wil eerst een overzicht van per jaar, per land de gemiddelde Influenza activiteit, Knokkelkoorts activiteit, kindersterfte, levensverwachting, geboorten en populatie over de periode van 2002 tot 2015. Ik verwacht dat er meer kindersterfte heeft plaatsgevonden in landen waarin in een bepaald jaar de Influenza of Knokkelkoorts activiteit hoog was. # Bereken de gemiddelden van de variabelen per jaar en land: FLU &lt;- flu_dengue_gapminder %&gt;% group_by(Country, Year) %&gt;% summarise(Gem_Influenza_act = mean(Influenza_activity)) DENG &lt;- flu_dengue_gapminder %&gt;% group_by(Country, Year) %&gt;% summarise(Gem_Knokkelkoorts_act = mean(Dengue_activity)) MORT &lt;- flu_dengue_gapminder %&gt;% group_by(Country, Year) %&gt;% summarise(Gem_kindersterfte = mean(infant_mortality)) LIFE &lt;- flu_dengue_gapminder %&gt;% group_by(Country, Year) %&gt;% summarise(Gem_levensverwachting= mean(life_expectancy)) FERT &lt;- flu_dengue_gapminder %&gt;% group_by(Country, Year) %&gt;% summarise(Gem_geboorten = mean(fertility)) POPU &lt;- flu_dengue_gapminder %&gt;% group_by(Country, Year) %&gt;% summarise(Gem_populatie = mean(population)) # Voeg de gemiddelden samen tot een tabel: desc_stat &lt;- flu_dengue_gapminder %&gt;% select(Country, Year) %&gt;% unique %&gt;% mutate(FLU, DENG, MORT, LIFE, FERT, POPU) %&gt;% arrange(Year) # Voorbeeld van laatste 10 rijen: ## Om één of andere reden verhelpt &#39;latex_options = &quot;scale_down&quot;&#39; niet het buiten de marges vallen van de tabel... kbl(tail(desc_stat, 10), caption = &quot;__Per jaar, per land de gemiddelden van de gemeten variabelen__&quot;) %&gt;% kable_styling(full_width = F, bootstrap_options = &quot;striped&quot;, position = &quot;left&quot;, latex_options = &quot;scale_down&quot;) %&gt;% column_spec(1:2, bold = TRUE) Table 8.2: Per jaar, per land de gemiddelden van de gemeten variabelen Country Year Gem_Influenza_act Gem_Knokkelkoorts_act Gem_kindersterfte Gem_levensverwachting Gem_geboorten Gem_populatie Poland 2015 1956 NA 4.5 77.6 1.44 38611794 Romania 2015 23679 NA 9.7 75.2 1.45 19511324 Russia 2015 21447 NA 8.2 71.0 1.61 143456918 South.Africa 2015 98940 NA NA NA NA NA Spain 2015 4863 NA 3.5 82.6 1.53 46121699 Sweden 2015 328 NA 2.4 82.1 1.93 9779426 Switzerland 2015 6390 NA 3.4 83.0 1.55 8298663 Ukraine 2015 12101 NA 7.7 71.5 1.49 44823765 United.States 2015 61295 NA NA NA NA NA Uruguay 2015 4195 NA 8.7 76.8 2.03 3431555 Ik ben A) geïnteresseerd in de trends van Influenza en Knokkelkoorts activiteit door de jaren heen en wil B) het verband tussen deze activiteit en kindersterfte toetsen. Figure 8.1: Influenza activiteit door de jaren heen. Voor 29 landen het aantal Influenza gevallen van 2002 tot en met 2015. Figure 8.2: Knokkelkoorts activiteit door de jaren heen. Voor 4 landen het aantal Knokkelkoorts gevallen van 2002 tot en met 2015. Figuur 8.1 laat voor vrijwel alle landen twee grote pieken in Influenza activiteit zien in 2009 en 2014. Figuur 8.2 laat één grote piek in Knokkelkoorts activiteit zien in 2009 voor de vier bijgehouden landen. # Verband tussen Influenza activiteit en kindersterfte # Filter missende waarden weg: fdg3 &lt;- flu_dengue_gapminder %&gt;% filter(Influenza_activity &gt; 0 &amp; infant_mortality &gt; 0) # Voer correlatie test uit: cor.test(fdg3$Influenza_activity, fdg3$infant_mortality, method=c(&quot;pearson&quot;)) #p-value = 0.6713, geen stat. sig. verband ## ## Pearson&#39;s product-moment correlation ## ## data: fdg3$Influenza_activity and fdg3$infant_mortality ## t = 0.42482, df = 301, p-value = 0.6713 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.08844289 0.13677987 ## sample estimates: ## cor ## 0.0244791 Figure 8.3: Per land het verband tussen Influenza activiteit en kindersterfte door de jaren heen. Voor 29 landen is van 2002 tot en met 2015 per jaar het aantal Influenza gevallen en de sterfte onder kinderen gemeten. # Verband tussen Knokkelkoorts activiteit en kindersterfte # Filter missende waarden weg: fdg4 &lt;- flu_dengue_gapminder %&gt;% filter(Dengue_activity &gt; 0 &amp; infant_mortality &gt; 0) # Voer correlatie test uit: cor.test(fdg4$Dengue_activity, fdg4$infant_mortality, method=c(&quot;pearson&quot;)) #p-value = 0.0008, wel stat. sig. verband ## ## Pearson&#39;s product-moment correlation ## ## data: fdg4$Dengue_activity and fdg4$infant_mortality ## t = -3.5682, df = 50, p-value = 0.000804 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.6442119 -0.2025123 ## sample estimates: ## cor ## -0.4505146 Figure 8.4: Per land het verband tussen Knokkelkoorts acitviteit en kindersterfte door de jaren heen. Voor 29 landen is van 2002 tot en met 2015 per jaar het aantal Knokkelkoorts gevallen en de sterfte onder kinderen gemeten. Conclusie Figuren 8.1 en 8.2 laten een min of meer overeenkomend patroon zien, misschien wordt de activiteit van de virussen door één of meerdere dezelfde parameters beïnvloed. Gebaseerd op de correlatie coëfficienten van 0.02 en -0.45 voor respectievelijk een verband tussen kindersterfte en Inlfuenza activiteit en kindersterfte en Knokkelkoorts activiteit, lijkt er geen positief (of negatief) verband te zijn tussen uitbraken van deze virussen en kindersterfte. "],["vaardigheid-7-een-r-package-maken.html", "9 Vaardigheid 7: Een R package maken", " 9 Vaardigheid 7: Een R package maken R packages zijn collecties van functions en datasets die gebruikt worden om tools te delen binnen de community. Van het inlezen van ruwe data tot het maken van tabellen en grafieken: overal worden packages voor gebruikt. Ik heb zelf ook een R package gemaakt: {paratests}. Dit package dient om het uitvoeren van (non)-parametrische toetsen makkelijker en beter reproduceerbaar te maken. Op dit moment bestaat het package uit vier functions: één voor een staafdiagram van een variabele gemiddelde per groep, één voor een Shapiro Wilk test, één voor een one-way ANOVA en één voor een puntgrafiek van variabelen met hun correlatie test resultaten. Lees in de README via deze repository hoe dit package geïnstalleerd en gebruikt moet worden. "],["vaardigheid-8-rmarkdowns-parameteriseren.html", "10 Vaardigheid 8: RMarkdowns parameteriseren 10.1 ECDC data nieuwgemelde COVID-19-gevallen en -doden", " 10 Vaardigheid 8: RMarkdowns parameteriseren Vaak wilt men de parameters binnen één analyse kunnen variëren, zoals de dataset waarop de analyse wordt uitgevoerd. Hieronder laat ik met een voorbeeld zien, dat ik RMarkdown parameterisatie kan gebruiken om soepel te switchen tussen parameters. 10.1 ECDC data nieuwgemelde COVID-19-gevallen en -doden Gebaseerd op publieke data van de European Center for Disease Prevention and Control (ECDC), heb ik een geparameteriseerd RMarkdown rapport geschreven dat voor een gegeven land en periode per dag het aantal nieuwgemelde COVID-19-gevallen en -doden laat zien. De te variëren parameters worden aan de YAML header toegevoegd binnen het ‘params:’ veld en ingesteld volgens bijv.: parameter_1: karakter parameter_2: numerieke waarde parameter_3: numerieke waarde Het is onmogelijk gebleken om een numerieke range op te geven als parameter, bijv. maand 3 t/m 5. Daarom heb ik besloten om een code te schrijven die voor elke opgegeven maand ook de gevallen en doden van de maand ervoor en erna laat zien. In een R chunk wordt een parameter aangehaald met: params$parameter_naam. Klik hier voor een voorbeeld van het rapport voor Nederland in februari, maart en april 2022. Het is onmogelijk gebleken om parameters toe te voegen aan een Gitbook. "],["referenties.html", "11 Referenties", " 11 Referenties "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
